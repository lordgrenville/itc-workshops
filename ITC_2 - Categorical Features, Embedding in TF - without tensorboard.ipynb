{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ITC_2 - Categorical Features, Embedding in TF - without tensorboard.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"oaMVbb7CYJIz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"63b54e45-97a4-4b39-d5c5-61f92cd62bc0"},"cell_type":"code","source":["# Israei Tech Challenge - Part 2 of 4\n","# Welcome to the ITC Taboola workshop. In this workshop we will address a real world problem:\n","# have a list of users and items (commercials) and their features. \n","# Lets try to predict the probablilty of a click (a user clicking on the commercial). \n","\n","# After only using only numerical features, it's time to use our categorical features!\n","# To Do that we'll need to use embedding in our tensor flow graph. \n","\n","# Let's start with basic imports. \n","import pandas as pd \n","import numpy as np\n","from collections import Counter, defaultdict\n","import ast\n","import os\n","import operator\n","import csv\n","from numbers import Number\n","from tensorflow.contrib.tensorboard.plugins import projector\n","import tensorflow as tf\n","import matplotlib.pyplot as pltb \n","%matplotlib inline\n","low_memory=False\n","\n","# Read Data\n","data = pd.read_csv('ITC_20K.csv')\n","\n","# Basic clean-up\n","data.replace('', np.nan, inplace=True)\n","data = data.dropna()\n","data.head(2)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_id</th>\n","      <th>content_category</th>\n","      <th>ad_type</th>\n","      <th>quality_level</th>\n","      <th>source_item_type</th>\n","      <th>syndicator_id</th>\n","      <th>target_id</th>\n","      <th>campaign_id</th>\n","      <th>title</th>\n","      <th>campaign_language</th>\n","      <th>...</th>\n","      <th>region</th>\n","      <th>browser_name</th>\n","      <th>user_clicks</th>\n","      <th>user_recs</th>\n","      <th>prev_syndicator_clicks</th>\n","      <th>target_recs</th>\n","      <th>campaign_recs</th>\n","      <th>user_category_clicks</th>\n","      <th>user_category_recs</th>\n","      <th>is_click</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-4.061510e+18</td>\n","      <td>sports</td>\n","      <td>DIRECT_RESPONSE</td>\n","      <td>HIGH</td>\n","      <td>SEARCH</td>\n","      <td>1028792</td>\n","      <td>-8.476730e+18</td>\n","      <td>232405</td>\n","      <td>This game will keep you up all night!</td>\n","      <td>en</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>Firefox</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n","      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-6.248340e+18</td>\n","      <td>fashion</td>\n","      <td>DIRECT_RESPONSE_TIER2</td>\n","      <td>MEDIUM</td>\n","      <td>SEARCH</td>\n","      <td>1058384</td>\n","      <td>-8.177870e+18</td>\n","      <td>722841</td>\n","      <td>People With 5-49 Vehicles Have Discovered This...</td>\n","      <td>en</td>\n","      <td>...</td>\n","      <td>TX</td>\n","      <td>Microsoft Edge</td>\n","      <td>3</td>\n","      <td>562</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1....</td>\n","      <td>0.0 0.0 0.0 0.0 0.0 2.9620843 18.657581 5.1518...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows Ã— 26 columns</p>\n","</div>"],"text/plain":["      source_id content_category                ad_type quality_level  \\\n","0 -4.061510e+18           sports        DIRECT_RESPONSE          HIGH   \n","1 -6.248340e+18          fashion  DIRECT_RESPONSE_TIER2        MEDIUM   \n","\n","  source_item_type  syndicator_id     target_id  campaign_id  \\\n","0           SEARCH        1028792 -8.476730e+18       232405   \n","1           SEARCH        1058384 -8.177870e+18       722841   \n","\n","                                               title campaign_language  \\\n","0              This game will keep you up all night!                en   \n","1  People With 5-49 Vehicles Have Discovered This...                en   \n","\n","     ...    region    browser_name  user_clicks user_recs  \\\n","0    ...         2         Firefox            0        13   \n","1    ...        TX  Microsoft Edge            3       562   \n","\n","  prev_syndicator_clicks target_recs campaign_recs  \\\n","0                      0           0             1   \n","1                      0           0             2   \n","\n","                                user_category_clicks  \\\n","0  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....   \n","1  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1....   \n","\n","                                  user_category_recs  is_click  \n","0  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....         1  \n","1  0.0 0.0 0.0 0.0 0.0 2.9620843 18.657581 5.1518...         0  \n","\n","[2 rows x 26 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"mJh4MW2cYJJG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# These are the features which have a categorical value for their columns. \n","\n","features_for_embedding =['source_id','content_category','ad_type','quality_level','source_item_type', \n","                         'syndicator_id','target_id','campaign_id','campaign_language','user_id',\n","                         'browser_platform', 'os_family','country_code','os_name','country','region', 'browser_name']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I89iNd12YJJS","colab_type":"text"},"cell_type":"markdown","source":["# (ANALYSIS) LOOKING AT THE DATA\n","How many unique values there're for each category?\n","How does the distribution looks like? (how many occurances for each value within each category?)"]},{"metadata":{"id":"Dif6ZeqfYJJV","colab_type":"text"},"cell_type":"markdown","source":["# (CODING) PREPROCESSING:\n","For each category column we wish to create *another* column for representing the possible values as integers (like enum)\n","1. The new column name should be same as original with the suffix \"_mapped\"\n","2. Start your indexing from 1 - keeping \"0\" for OOV (Out Of Volcabulary)\n","3. Pay attention to deside on an OOV threshold (num occurances).\n","4. Your output should be both:\n","\n","    4.1 New columns in the original dataframe\n","\n","    4.2 A dictionary of dictionaries named \"look_up_dict\": which maps from category_feature to a look_up dictionary (key: category_value, value: index)\n","    \n","data[\"sourced_id_mapped\"] = ...\n","\n","look_up_dict = {\"source_id\": {\"I am a possible value\": 1, \"OOV\": 0, ...}, \"content_category\": {\"OOV\":0, \"good\": 3,...},...}"]},{"metadata":{"id":"yZ9L8vuAYJJY","colab_type":"text"},"cell_type":"markdown","source":["# your solution"]},{"metadata":{"id":"-bHlAW39YJJb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"_kV--vJxYJJj","colab_type":"text"},"cell_type":"markdown","source":["# The code we give you:"]},{"metadata":{"id":"tjFTL8CzYJJm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Split into train, test sets\n","msk = np.random.rand(len(data)) < 0.8 \n","train = data[msk]\n","test = data[~msk]\n","\n","train = train.dropna()\n","test = test.dropna()\n","\n","# Create label\n","y_train = train[\"is_click\"]\n","del train[\"is_click\"]\n","y_test = test[\"is_click\"]\n","del test[\"is_click\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YK5FJZxFYJJs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["EMBEDDINGS_COLLECTION_NAME = \"embeddings\"\n","# a function for adding a categorical placeholder\n","def add_categorical_placeholder(input_name):\n","    batch_size = None  # using dynamic batch\n","    placeholder = tf.placeholder(tf.int32, shape=batch_size, name=input_name)\n","    tf.add_to_collection(\"input\", placeholder)\n","    return placeholder\n","\n","# a function that takes a placeholder and creates embedding for it\n","def add_categorical_embedding(input_placeholder, input_dim, output_dim):\n","    input_name = input_placeholder.op.name\n","    uniform = tf.random_uniform(shape=[input_dim, output_dim],minval=0.05,maxval=0.05)\n","    emb_weights = tf.Variable(initial_value=uniform, name=('{}_weights'.format(input_name)))\n","    tf.add_to_collection(EMBEDDINGS_COLLECTION_NAME, emb_weights)\n","    emb = tf.nn.embedding_lookup(emb_weights, input_placeholder, name=('{}_lookup'.format(input_name)))\n","    emb.set_shape([None, output_dim])\n","    return emb"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S3hIjD6VYJJ2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["embedding_size = 4\n","\n","def create_embeddings_for_all_features(features_for_embedding, look_up_dict):\n","    embeddings = []\n","    placeholder_list = []\n","\n","    feed_dict = {}\n","    num_features = 0\n","    for feature in features_for_embedding:\n","        input_placeholder = add_categorical_placeholder(feature+'_mapped')\n","        placeholder_list.append(input_placeholder)\n","        emb = add_categorical_embedding(input_placeholder, len(look_up_dict[feature]), embedding_size)\n","        \n","        embeddings.append(emb)\n","        num_features += embedding_size \n","    return num_features, placeholder_list, embeddings"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TNIQEGStYJJ-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def _safe_encode(value_0):\n","    if isinstance(value_0, Number):\n","        value_0 = str(value_0)\n","    try:\n","        value = value_0.encode(\"utf8\")\n","    except:\n","        value = value_0\n","    return value\n","  \n","def create_embedding_metadata(embedding_name, embedding_lookup, model_log_dir):\n","    sorted_emb = sorted(embedding_lookup.items(), key=operator.itemgetter(1))\n","    embedding_filename = embedding_name + '.tsv'\n","    metadata_path = os.path.join(model_log_dir, embedding_filename)\n","    with open(metadata_path, 'wb') as f:\n","        metadata_writer = csv.writer(f, delimiter='\\t')\n","        for value in sorted_emb:\n","            value = _safe_encode(value[0])\n","            if embedding_name in ['target_id']:\n","                metadata_writer.writerow(['#'+value])  # add some char so tensorboard will show as string\n","            else:\n","                metadata_writer.writerow([value])\n","\n","    return embedding_filename\n","\n","def project_embeddings():\n","    embedding_projector = projector.ProjectorConfig()\n","    metadata_paths = {}\n","    \n","    for i in range(len(features_for_embedding)):\n","        embedding_name = features_for_embedding[i]\n","        metadata_paths[embedding_name] = create_embedding_metadata(embedding_name, look_up_dict[embedding_name], model_log_dir)\n","        \n","    embeddings_vars = tf.get_collection_ref(EMBEDDINGS_COLLECTION_NAME)\n","    for embedding_var in embeddings_vars:\n","        embedding = embedding_projector.embeddings.add()\n","        embedding_name = embedding_var.name[:-len(\"_mapped_weights:0\")]\n","        embedding.tensor_name = embedding_var.name\n","        embedding.metadata_path = metadata_paths[embedding_name]\n","\n","    projection_summary_writer = tf.summary.FileWriter(model_log_dir, sess.graph)\n","    projector.visualize_embeddings(projection_summary_writer, embedding_projector)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TTsrrYuvYJKI","colab_type":"text"},"cell_type":"markdown","source":["# Building the graph and training"]},{"metadata":{"id":"XrVN-YxuYJKK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# ! rm -rf /tmp/taboola_tutorial/logs/*"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9DVOHc7UYJKT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"63cb8935-dff7-448b-b729-6a329bdc3cdc"},"cell_type":"code","source":["# This is the same code as before! except we move the check on out test dataframe inside the loop,\n","# so we can track the improvement of our model \n","\n","# Parameters\n","num_samples = train.shape[0]\n","batch_size = 50\n","training_epochs=3\n","total_batch = int(num_samples/batch_size)\n","learning_rate = 0.25\n","\n","# TF model\n","# This is where we start creating our TF graph\n","tf.reset_default_graph()\n","# tf Graph Input\n","num_features, placeholder_list, embeddings = create_embeddings_for_all_features(features_for_embedding, look_up_dict)\n","    \n","y = tf.placeholder(tf.float32, [None, 1])\n","\n","# Set model weights\n","x = tf.concat(axis=1, values=embeddings, name='concat')\n","W = tf.Variable(tf.random_normal([num_features, 1], stddev=0.15), name=\"weights\")\n","b = tf.Variable(tf.zeros([1]), name=\"bias\")\n","\n","pred = tf.sigmoid(tf.matmul(x, W) + b)\n","\n","# Minimize error using MSE\n","# cost = tf.reduce_sum(tf.square(y-pred))\n","cost = tf.losses.mean_squared_error(labels = y, predictions = pred)\n","\n","# Gradient Descent\n","global_step = tf.Variable(0,name='global_step', trainable=False)\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost, global_step=global_step)\n","\n","# Test model\n","correct_prediction = tf.equal(tf.round(pred), y)\n","# Calculate accuracy\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","# Define test_feed_dict once:\n","test_feed_dict = {}\n","for placeholder in placeholder_list:\n","    feature = placeholder.name[:-2]\n","    test_feed_dict[placeholder] = test[feature].values\n","test_feed_dict[y] = y_test\n","test_feed_dict[y] = test_feed_dict[y].values.reshape([len(y_test),1])\n","\n","# Initialize the variables (i.e. assign their default value)\n","init = tf.global_variables_initializer()\n","saver = tf.train.Saver()\n","model_log_dir = \"/tmp/taboola_tutorial/logs\"\n","# Start training\n","sess = tf.Session()\n","with sess:\n","#     summary_writer = tf.summary.FileWriter(model_log_dir + '/train', sess.graph)\n","#     summary_writer_test = tf.summary.FileWriter(model_log_dir + '/test', sess.graph)\n","    loss_summary = tf.summary.scalar('per_batch_loss', cost)\n","    merge_summaries_op = tf.summary.merge_all()\n","    # Run the initializer\n","    sess.run(init)\n","\n","    # Training cycle\n","    for epoch in range(training_epochs):\n","        avg_cost = 0.\n","\n","        # Loop over all batches\n","        for i in range(total_batch):\n","            feed_dict = {}\n","         \n","            for placeholder in placeholder_list:\n","                feature = placeholder.name[:-2]\n","                feed_dict[placeholder] = train[feature].iloc[i*batch_size : (i+1)*batch_size].values\n","\n","            feed_dict[y] = y_train.iloc[i*batch_size : (i+1)*batch_size]\n","            feed_dict[y] = feed_dict[y].values.reshape([batch_size,1])\n","\n","            # Run optimization op (backprop) and cost op (to get loss value)\n","            _, c, merged_summary, current_global_step = sess.run([optimizer, cost, merge_summaries_op, global_step], feed_dict)\n","#             summary_writer.add_summary(merged_summary,current_global_step)\n","            # Compute average loss\n","            avg_cost += c / (1.0*total_batch)\n","            \n","        print current_global_step\n","        train_summary = tf.Summary(value=[tf.Summary.Value(tag=\"loss\", simple_value=avg_cost)])\n","#         summary_writer.add_summary(train_summary, current_global_step)\n","        # Calc test error:\n","        test_loss = sess.run(cost, test_feed_dict)\n","        test_summary = tf.Summary(value=[tf.Summary.Value(tag=\"loss\", simple_value=test_loss)])\n","#         summary_writer_test.add_summary(test_summary, current_global_step)\n","        \n","        # Display logs per epoch step\n","        print \"Epoch:\", '%02d' % (epoch+1)\n","        print \"train error:\\t\", avg_cost\n","        print \"test error:\\t\", test_loss\n","        print(\"Accuracy:\", accuracy.eval(test_feed_dict))\n","    \n","#         saver.save(sess, os.path.join(model_log_dir, \"model.ckpt\"), current_global_step)\n","#     summary_writer.flush() \n","#     summary_writer_test.flush() \n","# project_embeddings()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["319\n","Epoch: 01\n","train error:\t0.222467447616\n","test error:\t0.204587\n","('Accuracy:', 0.70306224)\n","638\n","Epoch: 02\n","train error:\t0.206358872097\n","test error:\t0.202264\n","('Accuracy:', 0.70306224)\n","957\n","Epoch: 03\n","train error:\t0.204229066505\n","test error:\t0.201157\n","('Accuracy:', 0.70205826)\n"],"name":"stdout"}]},{"metadata":{"id":"8tOopRPwYJKe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Run TensorBoard\n","import subprocess\n","cmd = 'tensorboard --logdir ' + model_log_dir\n","p = subprocess.Popen(cmd, shell=True)\n","\n","# -> navigate to http://127.0.0.1:6006/\n","# go to the \"projector\" tab\n","# on the left: move from \"train\" directory to \".\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"-oALLfH-YJKk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}